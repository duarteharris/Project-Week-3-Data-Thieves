{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['virusds.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'README.md',\n",
       " 'virusds.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json \n",
    "from pandas.io.json import json_normalize\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from getpass import getpass\n",
    "import this\n",
    "\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ds into dataframe\n",
    "virus = pd.read_csv(\"virusds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      Sno                 Date   Province/State Country          Last Update  \\\n",
       "0      1  01/22/2020 12:00:00            Anhui   China  2020-01-22 12:00:00   \n",
       "1      2  01/22/2020 12:00:00          Beijing   China  2020-01-22 12:00:00   \n",
       "2      3  01/22/2020 12:00:00        Chongqing   China  2020-01-22 12:00:00   \n",
       "3      4  01/22/2020 12:00:00           Fujian   China  2020-01-22 12:00:00   \n",
       "4      5  01/22/2020 12:00:00            Gansu   China  2020-01-22 12:00:00   \n",
       "..   ...                  ...              ...     ...                  ...   \n",
       "695  696  02/03/2020 21:40:00       Boston, MA      US  2020-01-02 19:43:00   \n",
       "696  697  02/03/2020 21:40:00  Los Angeles, CA      US  2020-01-02 19:53:00   \n",
       "697  698  02/03/2020 21:40:00       Orange, CA      US  2020-01-02 19:53:00   \n",
       "698  699  02/03/2020 21:40:00      Seattle, WA      US  2020-01-02 19:43:00   \n",
       "699  700  02/03/2020 21:40:00        Tempe, AZ      US  2020-01-02 19:43:00   \n",
       "\n",
       "     Confirmed  Deaths  Recovered  \n",
       "0          1.0     0.0        0.0  \n",
       "1         14.0     0.0        0.0  \n",
       "2          6.0     0.0        0.0  \n",
       "3          1.0     0.0        0.0  \n",
       "4          0.0     0.0        0.0  \n",
       "..         ...     ...        ...  \n",
       "695        1.0     0.0        0.0  \n",
       "696        1.0     0.0        0.0  \n",
       "697        1.0     0.0        0.0  \n",
       "698        1.0     0.0        0.0  \n",
       "699        1.0     0.0        0.0  \n",
       "\n",
       "[700 rows x 8 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus\n",
    "virus.shape\n",
    "virus.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how prevalent missing values are in the data\n",
    "# defining a function to check null values and null values %:\n",
    "def null_cols(ds):\n",
    "    \"\"\"check whether the value in each field is missing (null) and return either \n",
    "    True or False for each field, totaling up the number of True values by column.\"\"\"\n",
    "    return ds.isnull().sum()\n",
    "\n",
    "def na_cols(ds):\n",
    "    \"\"\"Does the same as null_cols, but returns the value as a percentage. \n",
    "    Useful to decide where to drop.\"\"\"\n",
    "    return ds.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols = null_cols(virus)\n",
    "na_cols = na_cols(virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno                 0\n",
       "Date                0\n",
       "Province/State    164\n",
       "Country             0\n",
       "Last Update         0\n",
       "Confirmed           0\n",
       "Deaths              0\n",
       "Recovered           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 164 in Provice/State\n",
    "null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno                0.00\n",
       "Date               0.00\n",
       "Province/State    23.43\n",
       "Country            0.00\n",
       "Last Update        0.00\n",
       "Confirmed          0.00\n",
       "Deaths             0.00\n",
       "Recovered          0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Province/State 23,43% null valls\n",
    "na_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a condition that will filter the data and show us only columns where the number \n",
    "# of null values were greater than zero for each dataset:\n",
    "\n",
    "null_cols[null_cols > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sno: 700 uniques',\n",
       " 'Date: 13 uniques',\n",
       " 'Province/State: 57 uniques',\n",
       " 'Country: 31 uniques',\n",
       " 'Last Update: 92 uniques',\n",
       " 'Confirmed: 183 uniques',\n",
       " 'Deaths: 15 uniques',\n",
       " 'Recovered: 36 uniques']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Unique entries per colum:\n",
    "[col + \": \" + str(len(virus[col].unique())) + \" uniques\" for col in virus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>696</td>\n",
       "      <td>02/03/2020 21:40:00</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-02 19:43:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>697</td>\n",
       "      <td>02/03/2020 21:40:00</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-02 19:53:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>698</td>\n",
       "      <td>02/03/2020 21:40:00</td>\n",
       "      <td>Orange, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-02 19:53:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>699</td>\n",
       "      <td>02/03/2020 21:40:00</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-02 19:43:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>700</td>\n",
       "      <td>02/03/2020 21:40:00</td>\n",
       "      <td>Tempe, AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-02 19:43:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sno                 Date   Province/State Country          Last Update  \\\n",
       "0      1  01/22/2020 12:00:00            Anhui   China  2020-01-22 12:00:00   \n",
       "1      2  01/22/2020 12:00:00          Beijing   China  2020-01-22 12:00:00   \n",
       "2      3  01/22/2020 12:00:00        Chongqing   China  2020-01-22 12:00:00   \n",
       "3      4  01/22/2020 12:00:00           Fujian   China  2020-01-22 12:00:00   \n",
       "4      5  01/22/2020 12:00:00            Gansu   China  2020-01-22 12:00:00   \n",
       "..   ...                  ...              ...     ...                  ...   \n",
       "695  696  02/03/2020 21:40:00       Boston, MA      US  2020-01-02 19:43:00   \n",
       "696  697  02/03/2020 21:40:00  Los Angeles, CA      US  2020-01-02 19:53:00   \n",
       "697  698  02/03/2020 21:40:00       Orange, CA      US  2020-01-02 19:53:00   \n",
       "698  699  02/03/2020 21:40:00      Seattle, WA      US  2020-01-02 19:43:00   \n",
       "699  700  02/03/2020 21:40:00        Tempe, AZ      US  2020-01-02 19:43:00   \n",
       "\n",
       "     Confirmed  Deaths  Recovered  \n",
       "0          1.0     0.0        0.0  \n",
       "1         14.0     0.0        0.0  \n",
       "2          6.0     0.0        0.0  \n",
       "3          1.0     0.0        0.0  \n",
       "4          0.0     0.0        0.0  \n",
       "..         ...     ...        ...  \n",
       "695        1.0     0.0        0.0  \n",
       "696        1.0     0.0        0.0  \n",
       "697        1.0     0.0        0.0  \n",
       "698        1.0     0.0        0.0  \n",
       "699        1.0     0.0        0.0  \n",
       "\n",
       "[700 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-8797fbef0908>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-8797fbef0908>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    \"\"\"Adding col names to a list to be droped; in this case as long as the col has a\u001b[0m\n\u001b[0m                                                                                      \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "DON'T RUN THIS CELL YET!!!\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Judgement call: droping information that we don't think it's going to be very useful \n",
    "# to our analysis (removing those columns from your datasets) with the drop method.\n",
    "# We will add these column names to a list, and then we will pass those columns to the \n",
    "# drop method and indicate that we want columns (not rows) dropped by setting the axis \n",
    "# parameter to 1.\n",
    "\n",
    "# defining a function to create a list:\n",
    "def drop_cols(bad_cols):\n",
    "    \"\"\"Adding col names to a list to be droped; in this case as long as the col has a \n",
    "    single null value in it, since, in this case, if it has one, their all null.\"\"\"\n",
    "    return list(bad_cols[bad_cols > 0].index)\n",
    "\n",
    "# Droping the columns with null values is (always?) a judgment call. \n",
    "# In a discussion on analyticsvidhya.com \n",
    "# (what-should-be-the-allowed-percentage-of-missing-values/2456), the sugestion is to drop\n",
    "# after the 30% ceiling has been reached. Still, it will depend.\n",
    "\n",
    "# For starters I'll check what entities have the missing values and what don't;\n",
    "missing = merged.loc[(merged[\"ViewCount\"].notna() != True)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
